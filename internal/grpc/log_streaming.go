// Package grpc provides log streaming implementation for gRPC server.
//
// This file implements the LogStreamingService which receives real-time logs
// from worker pods and streams them to otto-handler via gRPC.
package grpc

import (
	"context"
	"fmt"
	"io"
	"log"
	"sync"
	"time"

	"google.golang.org/grpc/codes"
	"google.golang.org/grpc/status"

	"github.com/Team-5-CodeCat/ottoscaler/internal/k8s"
	pb "github.com/Team-5-CodeCat/ottoscaler/pkg/proto/v1"
)

// LogStreamingServer implements the LogStreamingService gRPC server.
//
// LogStreamingServerëŠ” Worker Podë“¤ì˜ ë¡œê·¸ë¥¼ ìˆ˜ì§‘í•˜ê³ 
// Otto-handlerë¡œ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°í•˜ëŠ” gRPC ì„œë²„ì…ë‹ˆë‹¤.
type LogStreamingServer struct {
	pb.UnimplementedLogStreamingServiceServer

	k8sClient         *k8s.Client
	ottoHandlerClient *OttoHandlerClient

	// Active streaming sessions
	sessions map[string]*StreamingSession
	mu       sync.RWMutex

	// Configuration
	maxSessionsPerWorker int
	streamTimeout        time.Duration
	maxRetries           int
	retryDelay           time.Duration
}

// StreamingSession represents an active log streaming session
//
// StreamingSessionì€ í™œì„± ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë° ì„¸ì…˜ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
type StreamingSession struct {
	SessionID  string
	WorkerID   string
	TaskID     string
	CreatedAt  time.Time
	LastActive time.Time
	LogCount   int64
	ErrorCount int64
	IsActive   bool

	// Connection management
	currentConnections int
	maxConnections     int
	retryCount         int

	// Streaming channels
	logStream   chan *pb.LogEntry
	errorStream chan error
	stopChan    chan struct{}
	mu          sync.RWMutex
}

// NewLogStreamingServer creates a new log streaming server instance.
//
// NewLogStreamingServerëŠ” ìƒˆë¡œìš´ ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë° ì„œë²„ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
func NewLogStreamingServer(k8sClient *k8s.Client, ottoHandlerAddress string, mockMode bool) *LogStreamingServer {
	// Create Otto-handler client
	ottoHandlerClient := NewOttoHandlerClient(ottoHandlerAddress, mockMode)

	// Connect to Otto-handler if not in mock mode
	if !mockMode || mockMode { // Always try to connect for now
		ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
		defer cancel()

		if err := ottoHandlerClient.Connect(ctx); err != nil {
			log.Printf("âš ï¸ Otto-handler ì—°ê²° ì‹¤íŒ¨: %v", err)
			log.Printf("ğŸ“¡ ë‚˜ì¤‘ì— ì—°ê²°ì„ ë‹¤ì‹œ ì‹œë„í•©ë‹ˆë‹¤...")
		}
	}

	return &LogStreamingServer{
		k8sClient:            k8sClient,
		ottoHandlerClient:    ottoHandlerClient,
		sessions:             make(map[string]*StreamingSession),
		maxSessionsPerWorker: 5,                // í•œ Workerë‹¹ ìµœëŒ€ 5ê°œ ë™ì‹œ ìŠ¤íŠ¸ë¦¼
		streamTimeout:        30 * time.Minute, // 30ë¶„ ì„¸ì…˜ íƒ€ì„ì•„ì›ƒ
		maxRetries:           3,                // ìµœëŒ€ 3íšŒ ì¬ì‹œë„
		retryDelay:           5 * time.Second,  // 5ì´ˆ ì¬ì‹œë„ ì§€ì—°
	}
}

// RegisterWorker handles worker registration requests.
//
// RegisterWorkerëŠ” Worker Pod ë“±ë¡ ìš”ì²­ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
// Worker Podê°€ ì‹œì‘ë  ë•Œ í˜¸ì¶œë˜ì–´ ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë° ì„¸ì…˜ì„ ì„¤ì •í•©ë‹ˆë‹¤.
func (s *LogStreamingServer) RegisterWorker(ctx context.Context, req *pb.WorkerRegistration) (*pb.RegistrationResponse, error) {
	if req == nil {
		return nil, status.Error(codes.InvalidArgument, "request cannot be nil")
	}

	if req.WorkerId == "" {
		return nil, status.Error(codes.InvalidArgument, "worker_id is required")
	}

	if req.TaskId == "" {
		return nil, status.Error(codes.InvalidArgument, "task_id is required")
	}

	log.Printf("ğŸ“‹ Worker ë“±ë¡ ìš”ì²­: worker_id=%s, task_id=%s", req.WorkerId, req.TaskId)

	s.mu.Lock()
	defer s.mu.Unlock()

	// Check if worker is already registered
	for _, session := range s.sessions {
		if session.WorkerID == req.WorkerId && session.IsActive {
			log.Printf("âš ï¸ Worker %sê°€ ì´ë¯¸ ë“±ë¡ë¨", req.WorkerId)
			return &pb.RegistrationResponse{
				Status:    pb.RegistrationResponse_ALREADY_REGISTERED,
				Message:   fmt.Sprintf("Worker %s is already registered", req.WorkerId),
				SessionId: session.SessionID,
				Config:    s.getDefaultLoggingConfig(),
			}, nil
		}
	}

	// Check session limits
	activeSessionsCount := s.countActiveSessionsForWorker(req.WorkerId)
	if activeSessionsCount >= s.maxSessionsPerWorker {
		log.Printf("âš ï¸ Worker %sì˜ ì„¸ì…˜ì´ ë„ˆë¬´ ë§ìŒ: %dê°œ", req.WorkerId, activeSessionsCount)
		return &pb.RegistrationResponse{
			Status:  pb.RegistrationResponse_SERVER_FULL,
			Message: fmt.Sprintf("Maximum sessions reached for worker %s", req.WorkerId),
		}, nil
	}

	// Create new session
	sessionID := fmt.Sprintf("%s-%d", req.WorkerId, time.Now().UnixNano())
	session := &StreamingSession{
		SessionID:          sessionID,
		WorkerID:           req.WorkerId,
		TaskID:             req.TaskId,
		CreatedAt:          time.Now(),
		LastActive:         time.Now(),
		IsActive:           true,
		currentConnections: 0,
		maxConnections:     3, // ìµœëŒ€ 3ê°œ ë™ì‹œ ì—°ê²°
		retryCount:         0,
		logStream:          make(chan *pb.LogEntry, 1000),
		errorStream:        make(chan error, 10),
		stopChan:           make(chan struct{}),
	}

	s.sessions[sessionID] = session

	log.Printf("âœ… Worker ë“±ë¡ ì™„ë£Œ: worker_id=%s, session_id=%s", req.WorkerId, sessionID)

	return &pb.RegistrationResponse{
		Status:    pb.RegistrationResponse_SUCCESS,
		Message:   fmt.Sprintf("Worker %s registered successfully", req.WorkerId),
		SessionId: sessionID,
		Config:    s.getDefaultLoggingConfig(),
	}, nil
}

// StreamLogs handles bidirectional log streaming.
//
// StreamLogsëŠ” ì–‘ë°©í–¥ ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë°ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
// Worker Podì—ì„œ ë¡œê·¸ë¥¼ ë°›ì•„ Otto-handlerë¡œ ì „ë‹¬í•˜ê³ 
// ì²˜ë¦¬ ê²°ê³¼ë¥¼ ë‹¤ì‹œ Worker Podë¡œ ì „ì†¡í•©ë‹ˆë‹¤.
func (s *LogStreamingServer) StreamLogs(stream pb.LogStreamingService_StreamLogsServer) error {
	log.Printf("ğŸ“¡ ìƒˆ ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë° ì—°ê²° ì„¤ì •ë¨")

	ctx := stream.Context()
	var currentSession *StreamingSession

	// Response goroutine for sending responses back to client
	responseChan := make(chan *pb.LogResponse, 100)
	defer close(responseChan)

	go func() {
		for {
			select {
			case response, ok := <-responseChan:
				if !ok {
					return
				}
				if err := stream.Send(response); err != nil {
					log.Printf("âŒ ë¡œê·¸ ì‘ë‹µ ì „ì†¡ ì‹¤íŒ¨: %v", err)
					return
				}
			case <-ctx.Done():
				return
			}
		}
	}()

	// Main streaming loop
	for {
		select {
		case <-ctx.Done():
			log.Printf("ğŸ“¡ ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë° ì—°ê²° ì¢…ë£Œ: %v", ctx.Err())
			if currentSession != nil {
				s.deactivateSession(currentSession.SessionID)
			}
			return ctx.Err()
		default:
			// Receive log entry from client
			logEntry, err := stream.Recv()
			if err == io.EOF {
				log.Printf("ğŸ“¡ í´ë¼ì´ì–¸íŠ¸ê°€ ë¡œê·¸ ìŠ¤íŠ¸ë¦¼ì„ ë‹«ìŒ")
				if currentSession != nil {
					s.deactivateSession(currentSession.SessionID)
				}
				return nil
			}
			if err != nil {
				log.Printf("âŒ ë¡œê·¸ ì—”íŠ¸ë¦¬ ìˆ˜ì‹  ì˜¤ë¥˜: %v", err)
				if currentSession != nil {
					s.deactivateSession(currentSession.SessionID)
				}
				return err
			}

			// Validate log entry
			if logEntry == nil {
				response := &pb.LogResponse{
					Status:  pb.LogResponse_DROP,
					Message: "log entry cannot be nil",
				}
				select {
				case responseChan <- response:
				case <-ctx.Done():
					return ctx.Err()
				}
				continue
			}

			// Find or validate session
			if currentSession == nil {
				session := s.findSessionByWorker(logEntry.WorkerId)
				if session == nil {
					log.Printf("âš ï¸ Worker %sì˜ ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ", logEntry.WorkerId)
					response := &pb.LogResponse{
						Status:  pb.LogResponse_DROP,
						Message: fmt.Sprintf("Worker %s not registered", logEntry.WorkerId),
					}
					select {
					case responseChan <- response:
					case <-ctx.Done():
						return ctx.Err()
					}
					continue
				}
				currentSession = session
				log.Printf("ğŸ“¡ ì„¸ì…˜ê³¼ ìŠ¤íŠ¸ë¦¼ ì—°ê²°: %s", session.SessionID)
			}

			// Process log entry
			if err := s.processLogEntry(ctx, logEntry, currentSession); err != nil {
				log.Printf("âŒ ë¡œê·¸ ì—”íŠ¸ë¦¬ ì²˜ë¦¬ ì˜¤ë¥˜: %v", err)
				response := &pb.LogResponse{
					Status:  pb.LogResponse_RETRY,
					Message: fmt.Sprintf("Processing error: %v", err),
				}
				select {
				case responseChan <- response:
				case <-ctx.Done():
					return ctx.Err()
				}
				continue
			}

			// Send success response
			currentSession.LogCount++
			response := &pb.LogResponse{
				Status:   pb.LogResponse_ACK,
				Message:  "Log received successfully",
				Sequence: currentSession.LogCount,
			}
			select {
			case responseChan <- response:
			case <-ctx.Done():
				return ctx.Err()
			}
		}
	}
}

// processLogEntry processes a single log entry
//
// processLogEntryëŠ” ë‹¨ì¼ ë¡œê·¸ ì—”íŠ¸ë¦¬ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
func (s *LogStreamingServer) processLogEntry(ctx context.Context, logEntry *pb.LogEntry, session *StreamingSession) error {
	// Update session activity
	session.mu.Lock()
	session.LastActive = time.Now()
	session.mu.Unlock()

	// Validate log entry fields
	if logEntry.WorkerId == "" {
		session.mu.Lock()
		session.ErrorCount++
		session.mu.Unlock()
		return fmt.Errorf("worker_id is required")
	}
	if logEntry.TaskId == "" {
		session.mu.Lock()
		session.ErrorCount++
		session.mu.Unlock()
		return fmt.Errorf("task_id is required")
	}
	if logEntry.Message == "" {
		session.mu.Lock()
		session.ErrorCount++
		session.mu.Unlock()
		return fmt.Errorf("message is required")
	}

	// Add timestamp if missing
	if logEntry.Timestamp == "" {
		logEntry.Timestamp = time.Now().Format(time.RFC3339)
	}

	// Set default level if missing
	if logEntry.Level == "" {
		logEntry.Level = "INFO"
	}

	// Set default source if missing
	if logEntry.Source == "" {
		logEntry.Source = "stdout"
	}

	// Attempt to forward to Otto-handler with retry logic
	if err := s.forwardLogEntryWithRetry(ctx, logEntry, session); err != nil {
		session.mu.Lock()
		session.ErrorCount++
		session.mu.Unlock()
		log.Printf("âš ï¸ ì¬ì‹œë„ í›„ì—ë„ ë¡œê·¸ ì—”íŠ¸ë¦¬ ì „ë‹¬ ì‹¤íŒ¨: %v", err)
		return err
	}

	return nil
}

// forwardLogEntryWithRetry forwards log entry with retry logic
//
// forwardLogEntryWithRetryëŠ” ì¬ì‹œë„ ë¡œì§ê³¼ í•¨ê»˜ ë¡œê·¸ ì—”íŠ¸ë¦¬ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.
func (s *LogStreamingServer) forwardLogEntryWithRetry(ctx context.Context, logEntry *pb.LogEntry, session *StreamingSession) error {
	var lastErr error

	for attempt := 0; attempt <= s.maxRetries; attempt++ {
		if attempt > 0 {
			// Wait before retry
			select {
			case <-time.After(s.retryDelay):
			case <-ctx.Done():
				return ctx.Err()
			}
		}

		// Attempt to forward the log entry
		if err := s.forwardLogEntry(ctx, logEntry, session); err != nil {
			lastErr = err
			log.Printf("âš ï¸ ë¡œê·¸ ì „ë‹¬ %dì°¨ ì‹œë„ ì‹¤íŒ¨: %v", attempt+1, err)
			continue
		}

		// Success
		if attempt > 0 {
			log.Printf("âœ… ë¡œê·¸ ì „ë‹¬ %dì°¨ ì‹œë„ì—ì„œ ì„±ê³µ", attempt+1)
		}
		return nil
	}

	return fmt.Errorf("log forwarding failed after %d attempts: %w", s.maxRetries+1, lastErr)
}

// forwardLogEntry forwards a single log entry to Otto-handler.
//
// forwardLogEntryëŠ” ë‹¨ì¼ ë¡œê·¸ ì—”íŠ¸ë¦¬ë¥¼ Otto-handlerë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.
func (s *LogStreamingServer) forwardLogEntry(ctx context.Context, logEntry *pb.LogEntry, session *StreamingSession) error {
	// Convert LogEntry to WorkerLogEntry for Otto-handler
	workerLogEntry := &pb.WorkerLogEntry{
		WorkerId:  logEntry.WorkerId,
		TaskId:    logEntry.TaskId,
		Timestamp: logEntry.Timestamp,
		Level:     logEntry.Level,
		Source:    logEntry.Source,
		Message:   logEntry.Message,
		PodMetadata: &pb.WorkerMetadata{
			PodName:   logEntry.WorkerId,
			Namespace: "default", // TODO: Get from actual context
			CreatedAt: session.CreatedAt.Format(time.RFC3339),
		},
		Metadata: logEntry.Metadata,
	}

	// Ensure log stream is started for this worker
	if s.ottoHandlerClient.GetActiveStreamCount() == 0 ||
		!s.isStreamActive(logEntry.WorkerId) {
		// Start new log stream
		if err := s.ottoHandlerClient.StartLogStream(ctx, logEntry.WorkerId, logEntry.TaskId); err != nil {
			log.Printf("âš ï¸ Worker %sì˜ ë¡œê·¸ ìŠ¤íŠ¸ë¦¼ ì‹œì‘ ì‹¤íŒ¨: %v", logEntry.WorkerId, err)
			return err
		}
		log.Printf("ğŸ“¡ Worker %sì˜ Otto-handler ë¡œê·¸ ìŠ¤íŠ¸ë¦¼ ì‹œì‘", logEntry.WorkerId)
	}

	// Forward the log entry
	if err := s.ottoHandlerClient.ForwardLogEntry(ctx, workerLogEntry); err != nil {
		log.Printf("âš ï¸ Otto-handlerë¡œ ë¡œê·¸ ì „ë‹¬ ì‹¤íŒ¨: %v", err)
		return err
	}

	return nil
}

// isStreamActive checks if a log stream is active for a worker.
//
// isStreamActiveëŠ” Workerì˜ ë¡œê·¸ ìŠ¤íŠ¸ë¦¼ì´ í™œì„± ìƒíƒœì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤.
func (s *LogStreamingServer) isStreamActive(workerID string) bool {
	_, _, exists := s.ottoHandlerClient.GetStreamStats(workerID)
	return exists
}

// getDefaultLoggingConfig returns default logging configuration
//
// getDefaultLoggingConfigëŠ” ê¸°ë³¸ ë¡œê¹… ì„¤ì •ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
func (s *LogStreamingServer) getDefaultLoggingConfig() *pb.LoggingConfig {
	return &pb.LoggingConfig{
		RateLimit:       100,  // ì´ˆë‹¹ ìµœëŒ€ 100ê°œ ë¡œê·¸
		BufferSize:      50,   // 50ê°œ ë¡œê·¸ ë²„í¼ë§
		MaxMessageSize:  1024, // 1KB ìµœëŒ€ ë©”ì‹œì§€ í¬ê¸°
		IncludeMetadata: true, // ë©”íƒ€ë°ì´í„° í¬í•¨
	}
}

// countActiveSessionsForWorker counts active sessions for a worker
//
// countActiveSessionsForWorkerëŠ” íŠ¹ì • Workerì˜ í™œì„± ì„¸ì…˜ ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
func (s *LogStreamingServer) countActiveSessionsForWorker(workerID string) int {
	count := 0
	for _, session := range s.sessions {
		if session.WorkerID == workerID && session.IsActive {
			count++
		}
	}
	return count
}

// findSessionByWorker finds an active session for a worker
//
// findSessionByWorkerëŠ” íŠ¹ì • Workerì˜ í™œì„± ì„¸ì…˜ì„ ì°¾ìŠµë‹ˆë‹¤.
func (s *LogStreamingServer) findSessionByWorker(workerID string) *StreamingSession {
	s.mu.RLock()
	defer s.mu.RUnlock()

	for _, session := range s.sessions {
		if session.WorkerID == workerID && session.IsActive {
			return session
		}
	}
	return nil
}

// deactivateSession deactivates a streaming session
//
// deactivateSessionì€ ìŠ¤íŠ¸ë¦¬ë° ì„¸ì…˜ì„ ë¹„í™œì„±í™”í•©ë‹ˆë‹¤.
func (s *LogStreamingServer) deactivateSession(sessionID string) {
	s.mu.Lock()
	defer s.mu.Unlock()

	if session, exists := s.sessions[sessionID]; exists {
		session.IsActive = false
		close(session.stopChan)
		log.Printf("ğŸ”Œ ì„¸ì…˜ ë¹„í™œì„±í™”: %s (ì²˜ë¦¬ëœ ë¡œê·¸: %dê°œ)", sessionID, session.LogCount)
	}
}

// CleanupInactiveSessions removes inactive sessions periodically
//
// CleanupInactiveSessionsëŠ” ë¹„í™œì„± ì„¸ì…˜ì„ ì£¼ê¸°ì ìœ¼ë¡œ ì •ë¦¬í•©ë‹ˆë‹¤.
func (s *LogStreamingServer) CleanupInactiveSessions() {
	s.mu.Lock()
	defer s.mu.Unlock()

	cutoff := time.Now().Add(-s.streamTimeout)
	cleaned := 0

	for sessionID, session := range s.sessions {
		if !session.IsActive || session.CreatedAt.Before(cutoff) {
			delete(s.sessions, sessionID)
			cleaned++
		}
	}

	if cleaned > 0 {
		log.Printf("ğŸ§¹ ë¹„í™œì„± ì„¸ì…˜ %dê°œ ì •ë¦¬ë¨", cleaned)
	}
}

// GetActiveSessionsCount returns the number of active sessions
//
// GetActiveSessionsCountëŠ” í™œì„± ì„¸ì…˜ ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
func (s *LogStreamingServer) GetActiveSessionsCount() int {
	s.mu.RLock()
	defer s.mu.RUnlock()

	count := 0
	for _, session := range s.sessions {
		if session.IsActive {
			count++
		}
	}
	return count
}
